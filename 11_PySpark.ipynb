{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f413b17e",
   "metadata": {},
   "source": [
    "<a href=\"https://naomi-fridman.medium.com/install-pyspark-to-run-on-jupyter-notebook-on-windows-4ec2009de21f\">Install Pyspark with Jupyter notebook</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208aacb0",
   "metadata": {},
   "source": [
    "# Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Open-source distributed quering and processing engine. 100X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "read, transform, train, deploy statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark APIs - Java, Python, Scala, R, SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLlib, GraphX - Graph processing, Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dfa00e",
   "metadata": {},
   "source": [
    "## Resilient Distributed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "JVM - Java Virtual Machine, \n",
    "Apache Spark is distributed collection of immutable JVM objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "map()\n",
    "reduce()\n",
    "filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01440da1",
   "metadata": {},
   "source": [
    "## Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "they are immutable collection of data,\n",
    "distributed on nodes in a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ea510",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f64066",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETL  -  Extract Trasform Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resilient Distributed Dataset\n",
    "\n",
    "RDDs\n",
    "\n",
    "- Backbone Apache Spark\n",
    "- Parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([1,2, ('Raj', 15), 23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([\n",
    "    {'name': 'Tanmay'},\n",
    "    {'Car': 'Porshe'}\n",
    "]).collect()              # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda r: int(r[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter = data.filter(lambda r: r[16] =='2014')\n",
    "data_filter.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c54aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3890f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce()\n",
    "\n",
    "rdd.map(lambda r: r[1]).reduce(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9d9bb",
   "metadata": {},
   "source": [
    "### dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\n",
    "    'name': 'Akash',\n",
    "    'age': 21\n",
    "}\n",
    "y = {\n",
    "    'name': 'Akash',\n",
    "    'age': 21,\n",
    "    'color': 'red'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonRDD = sc.parallelize((\"\"\"\n",
    "    { \"id\":\"123\",\n",
    "      \"name\": 'Ravi',\n",
    "      \"age\": 19\n",
    "    }\"\"\",\n",
    "    \"\"\"\n",
    "    { \"id\":\"123\",\n",
    "      \"name\": 'Ravi',\n",
    "      \"age\": 19\n",
    "    }\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a066e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spark.read.json(jsonRDD)  # create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fc8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.createOrReplaceTempView(\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a234c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aecfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL queries\n",
    "\n",
    "\n",
    "spark.sql(\"select * from s\").collect()\n",
    "\n",
    "#databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.printSchema()\n",
    "\n",
    "# age: long \n",
    "# id: string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b18f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonRDD = sc.parallelize((\"\"\"\n",
    "    { \"id\":\"123\",\n",
    "      \"name\": 'Ravi',\n",
    "      \"age\": 19\n",
    "    }\"\"\",\n",
    "    \"\"\"\n",
    "    { \"id\":\"123\",\n",
    "      \"name\": 'Ravi',\n",
    "      \"age\": 19\n",
    "    }\"\"\")\n",
    ")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", LongType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "s = spark.createDataFrame(jsonRDD, schema)\n",
    "\n",
    "s.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.count() # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd644983",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.select(\"id\", \"age\").filter(\"age = 23\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329a7b2",
   "metadata": {},
   "source": [
    "## prepare DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1,5.9, 21, 'M'),\n",
    "    (2,5.9, 21, 'M'),\n",
    "    (3,5.9, 21, 'M'),\n",
    "    (4,5.9, 21, 'M')\n",
    "], ['id', 'height', 'age','gender'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe763c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47936729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where('id' == 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3859a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad397c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f521d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
